## Efectos del confinamiento en la calidad del aire de la Comunidad de Madrid

_Este proyecto es una pr치ctica docente. Su objetivo es poner en pr치ctica las t칠cnicas de Big Data y Machine Learning aprendidas._

_Este documento forma parte de un proyecto publicado en [https://github.com/Big-Data-Equipo-7/Proyecto](https://github.com/Big-Data-Equipo-7/Proyecto)_ 

### Integrantes del Grupo 7
* Alfonso Gallardo (Cient칤fico de datos)
* Ra칰l Herv치s (Analista de datos)
* Carmen Reina (Analista de negocio)
* Walter Ronceros (Arquitecto de datos)
* Susana Vara (Analista de datos - Representante)

### Limitaciones ###

Para este estudio damos por hecho ciertas limitaciones insalvables como son:

* No todas las estaciones contienen medici칩n de todos los agentes contaminantes.
* Las mediciones meteorol칩gicas no se pueden prever.
* El 칤ndice ICA (칈ndice Calidad del Aire) se obtiene de la medici칩n m치s adversa de 5 agentes contaminantes por lo que no puede utilizarse para buscar correlaciones directas.

### Tecnolog칤as 游늶

* Python 3.8.2
* Anaconda Navigator 3.0.1
* Docker 19.03.8
* Jupyter Notebook 6.0.3
* Spyder 
* Elasticsearch
* Databricks
* Google Colab

### Instrucciones para la reproducci칩n del trabajo

**A tener en cuenta:** *Los scripts est치n preparados para funcionar en rutas concretas y han de ejecutarse en el mismo orden para tener los resultados esperados.*

1. Ejecuci칩n del script _*1 - Generar datos de Madrid desagregado.py*_ para obtener el dataset que se utilizar치 en el siguiente punto (datosdefinitivos.csv).
2. Ejecuci칩n del [Notebook albergado en Colab](https://colab.research.google.com/drive/1hAkG64bXv-BuhfkH0_3qH2lx-pIUcLTK#scrollTo=nh7diHL592kF). Se guarda una copia dentro del proyecto con el nombre _*2 - Estudio datos de Madrid.ipynb*_. Hay que tener en cuenta de que la reproducci칩n de los modelos est치n preparadas para funcionar en Google Colab, la ejecuci칩n en local requiere algunas modificaciones del Notebook. 
3. Ejecuci칩n del script _*3 - Generar datosHistoricosCalidadDelAire.py*_ para obtener el dataset que se utilizar치 en el siguiente punto (datosHistoricosCalidadAire.csv)
4. Ejecuci칩n del Notebook Jupyter _*4 - Estudio datosHistoricosCalidadDelAire.ipynb*_ 

### Instrucciones para entorno de visualizaci칩n ###

Esta fase se realiza apoy치ndonos en dockers donde utilizaremos la pila **ELK**. 

Podr치s ver un video explicativo en el siguiente enlace [Video](https://photos.app.goo.gl/AvezfKMgfHQqV7C46)

#### Necesitar치s ####
* Instalar [Docker Desktop](https://www.docker.com/products/docker-desktop)
* Descarga de contenedor [sebp/elk](https://hub.docker.com/r/sebp/elk/)
* Arrancar el contender indicando los puertos para Elastic, Logstash y Kibana
* Copiar dataset al contenedor para procesarlo con Logstash
* Crear config para Logstash con nombre de index global_info
* Crear 칤ndice global_info con el mapeo del campo localizaci칩n para que el tipo de dato sea geo_point
* Ejecutamos logstash para realizar carga con el comando: logstash -f /opt/logstash/config/grupo7_BigData_global.config

*Para mas detalle consultar la _memoria._*

